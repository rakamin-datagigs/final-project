{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034eeb9a-ab39-4306-bfd6-f105a8ead035",
   "metadata": {},
   "source": [
    "# **Data Preprocessing - DataGigs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cacf3ae-c11e-499a-ae30-af7c08b1a3ca",
   "metadata": {},
   "source": [
    "- Devina\n",
    "- Hani Kurnia\n",
    "- Yudanta A\n",
    "- Mutiara Farianda\n",
    "- Linda\n",
    "- Rudiyanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e6e069-f576-4c86-8156-c6f6b344a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f5e667-f822-4b75-9d28-13906b7b64d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Course\\\\Rakamin Data scientist\\\\Final Project\\\\Week 9 intro finpro\\\\TravelInsurancePrediction.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCourse\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mRakamin Data scientist\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mFinal Project\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mWeek 9 intro finpro\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTravelInsurancePrediction.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 0\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Course\\\\Rakamin Data scientist\\\\Final Project\\\\Week 9 intro finpro\\\\TravelInsurancePrediction.csv'"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('D:\\Course\\Rakamin Data scientist\\Final Project\\Week 9 intro finpro\\TravelInsurancePrediction.csv')\n",
    "df = df.drop(labels='Unnamed: 0', axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8ab7a-3d8f-478c-b93a-2898bef97104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20e745-f636-41d2-9c4c-bfc2b0d7a922",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handle Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ad054-c3e6-47d2-914a-f9f8c643bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa nilai kosong fitur numerikal\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b8581-a151-4e1f-8229-30276b2cf411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa nilai kosong fitur kategorikal\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c17dbdb-5701-40b2-9cbd-cefebb12e142",
   "metadata": {},
   "source": [
    "Tidak terdapat missing value pada data yang akan digunakan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7dad78-7329-45bf-9ea5-0051033c661f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handle Duplicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0e24b-a6b8-4895-bee5-25b79e087b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b358d-1cae-4e1d-a53c-331fb232d88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated rows\n",
    "print(f'Jumlah row duplicated sebelum dihapus {df.duplicated().sum()}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'Jumlah row duplicated setelah dihapus {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9925cf9-6fe6-4fe8-afe0-7fdf6c9ce181",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Jumlah row tanpa data duplikat: {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f25b3-88c3-496f-a862-72cb7f0b0c8b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711476de-b2c6-4db3-9200-e52441c5d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = 6, 6\n",
    "rcParams['lines.linewidth'] = 3\n",
    "rcParams['xtick.labelsize'] = 'x-large'\n",
    "rcParams['ytick.labelsize'] = 'x-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d6440-45ae-4ba1-8c37-b525c08e5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = ['Age', 'AnnualIncome', 'FamilyMembers']\n",
    "for i in range(0, len(nums)):\n",
    "  plt.subplot(1, len(nums),i+1)\n",
    "  sns.boxplot(y=df[nums[i]],color=\"green\",orient='v')\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb9535-7234-48c2-9aed-fa72e8cb874b",
   "metadata": {},
   "source": [
    "Berdasarkan BoxPlot di atas, tidak terdapat outliers pada fitur numerikal untuk training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550f6b5-7583-486e-b55a-e53bafff55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membagi Jenis Fitur\n",
    "nums = ['Age', 'AnnualIncome', 'FamilyMembers']\n",
    "cats = df.drop(nums, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fcd582-c182-4249-93f4-27da6f188253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus Outlier dengan IQR\n",
    "\n",
    "for i in nums:\n",
    "    q1 = df[i].quantile(0.25)\n",
    "    q3 = df[i].quantile(0.75)\n",
    "    iqr = q3-q1\n",
    "    low_limit = q1 - (1.5 * iqr)\n",
    "    high_limit = q3 + (1.5 * iqr)\n",
    "    filtered_entries = ((df[i] >= low_limit) & (df[i] <= high_limit))\n",
    "    df = df[filtered_entries]\n",
    "    print(f'Jumlah baris setelah memfilter outlier feature {i}: {len(df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde3943-6c1e-4735-bdb4-cff308684816",
   "metadata": {},
   "source": [
    "**Kesimpulan**:\n",
    "Tidak terdapat outliers sehingga tidak ada row yang dibuang."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be96b43-fcb7-4c59-9d95-223cd975ec38",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962b739-8a04-4d4d-a61a-a347b273feab",
   "metadata": {},
   "source": [
    "Karena jumlah kolom data yang dimiliki dari dataset ini hanya sedikit (9 kolom), maka diputuskan untuk **menggunakan seluruh kolom yang ada sebagai feature untuk pemodelan Machine Learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f09d4-46b3-43f8-89c7-0a12fb619ab8",
   "metadata": {},
   "source": [
    "### Chi Square Test Untuk Korelasi Antar Fitur Kategorikal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fe3e9-efa6-466b-9172-a17e998ed115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import chi2 test\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250137b-0859-487d-89c2-56e2b51e6665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapping kolom ChronicDisease dan TravelInsurance menjadi tipe data Object untuk uji hipotesa Chi2 Test\n",
    "\n",
    "map_disease = {\n",
    "    0: 'No',\n",
    "    1: 'Yes'\n",
    "}\n",
    "\n",
    "map_insurance = {\n",
    "    0: 'No',\n",
    "    1: 'Yes'\n",
    "}\n",
    "\n",
    "df['ChronicDiseases'] = df['ChronicDiseases'].map(map_disease)\n",
    "df['TravelInsurance'] = df['TravelInsurance'].map(map_insurance)\n",
    "\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b586db1d-67de-42aa-a9ba-f581cef461a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghapus Duplikat untuk menyamakan jumlah row data\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c4a53-6c15-47c3-84a7-c09851ce8795",
   "metadata": {},
   "source": [
    "#### Uji Korelasi Antara Kolom Employment Type dengan Travel Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735fa48-9e83-4b99-86df-57041e219153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[\"Employment Type\"], df[\"TravelInsurance\"])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-squared test statistic: \", chi2)\n",
    "print(\"p-value: \", p)\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    print(\"The variables are correlated (reject H0)\")\n",
    "else:\n",
    "    print(\"The variables are independent (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075a927-bff5-439d-9286-09ca8692d73d",
   "metadata": {},
   "source": [
    "#### Uji Korelasi Antara Kolom GraduateOrNot dengan Travel Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fef0d-f108-4d65-a7dd-df0073f810c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[\"GraduateOrNot\"], df[\"TravelInsurance\"])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-squared test statistic: \", chi2)\n",
    "print(\"p-value: \", p)\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    print(\"The variables are correlated (reject H0)\")\n",
    "else:\n",
    "    print(\"The variables are independent (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ffcaa-f932-4e3a-b219-129d26d5dbac",
   "metadata": {},
   "source": [
    "#### Uji Korelasi Antara Kolom ChronicDiseases dengan Travel Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386be53a-5bef-4f1c-9312-18db5dbec0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[\"ChronicDiseases\"], df[\"TravelInsurance\"])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-squared test statistic: \", chi2)\n",
    "print(\"p-value: \", p)\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    print(\"The variables are correlated (reject H0)\")\n",
    "else:\n",
    "    print(\"The variables are independent (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d71f0-cd11-4419-9333-f8d485f7b3ec",
   "metadata": {},
   "source": [
    "#### Uji Korelasi Antara Kolom FrequentFlyer dengan Travel Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96288f09-b880-444d-8ab8-a11598014d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[\"FrequentFlyer\"], df[\"TravelInsurance\"])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-squared test statistic: \", chi2)\n",
    "print(\"p-value: \", p)\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    print(\"The variables are correlated (reject H0)\")\n",
    "else:\n",
    "    print(\"The variables are independent (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf7cbb-7fd4-48bd-9222-360779fb50d4",
   "metadata": {},
   "source": [
    "#### Uji Korelasi Antara Kolom EverTravelledAbroad dengan Travel Insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2618374e-55ab-404e-9e04-27c0b95f48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(df[\"EverTravelledAbroad\"], df[\"TravelInsurance\"])\n",
    "\n",
    "# Perform the chi-squared test\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(\"Chi-squared test statistic: \", chi2)\n",
    "print(\"p-value: \", p)\n",
    "\n",
    "# Interpret the results\n",
    "if p < 0.05:\n",
    "    print(\"The variables are correlated (reject H0)\")\n",
    "else:\n",
    "    print(\"The variables are independent (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3403fe5-0166-4467-b6a4-5b5b190bb486",
   "metadata": {},
   "source": [
    "#### Kesimpulan Hasil Pengujian Hipotesa Untuk Melihat Korelasi Antar Data Kategorikal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64548151-1e27-4bda-b852-c1ef44875dec",
   "metadata": {},
   "source": [
    "Berdasarkan hasil pengujian antara kolom-kolom kategorikal dengan target (TravelInsurance), kolom yang memiliki korelasi adalah sebagai berikut:\n",
    "\n",
    "- EmploymentType & TravelInsurance\n",
    "- FrequentFlyer & TravelInsurance\n",
    "- EverTravelledAbroad & TravelInsurance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630b4e8-555a-48a8-922c-374db4ca3259",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f456a32-d8c7-4fdc-873e-0531577d3641",
   "metadata": {},
   "source": [
    "1. Feature Income Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2a31f-d4cc-4eea-b8ae-9306b4fa53c3",
   "metadata": {},
   "source": [
    "Merujuk pada artikel dari [The Times in India](https://timesofindia.indiatimes.com/times-special/how-the-middle-class-has-turned-cities-into-indias-growth-engine/articleshow/95865472.cms), diketahui bahwa yang termasuk dengan income kelas menengah di India terdapat pada kisaran 5 lakh - 30 lakh (500,000 Rupees - 3,000,000 Rupees) pada tahun 2020. Dengan jarak hanya 1 tahun dari dataset (tahun 2019), diasumsikan tidak terdapat perbedaan kelas income yang signifikan sehingga informasi dari artikel dapat menjadi pedoman dalam melakukan Feature Extraction.\n",
    "\n",
    "Karena range income pada dataset hanya berkisar dari 300,000 - 1,800,000, maka pemisahan kelas income untuk Feature Extraction dibagi menjadi:\n",
    "\n",
    "- Low: Income < 500,000 Rupees\n",
    "- Medium: Income >500,000 Rupees dan < 1,500,000 Rupees\n",
    "- High: Income > 1,500,000 Rupees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3163c16-efd1-44b8-8a69-92162d7b2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IncomeGroup'] = np.where(df['AnnualIncome'] < 500001, 'Low',\n",
    "                             np.where(df['AnnualIncome'] < 1500001, 'Medium', 'High'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3cceba-d93d-480e-8e45-0c65d9eaf676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eecb6a0-4bb9-4450-954b-a9a29c0b1ac8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Tambahan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c22e7-d35c-46e5-8b65-df9dec1e738e",
   "metadata": {},
   "source": [
    "- Identitas Customer: Agar dapat membedakan mana yang merupakan data duplikat atau bukan.\n",
    "- Memiliki Asuransi Jiwa/Kesehatan: Apakah customer memiliki asuransi lainnya. Karena benefit dari asuransi perjalanan adalah mengcover semua biaya yang terjadi hanya pada suatu perjalanan sehingga ada kemungkinan customer yang telah memiliki asuransi lainnya tidak akan tertarik untuk membeli asuransi perjalanan.\n",
    "- Responded: Menginformasikan apakah pihak Travel Insurance sudah pernah melakukan marketing terhadap customer sebelumnya (baik via telepon atau email) dan apakah customer memberikan respon atau tidak.\n",
    "- Frequency: Frekuensi berkunjung customer ke web travel\n",
    "- PromotionType: Kolom yang menginformasikan jenis promosi terhadap customer, dimana: 1. untuk orang yang sudah pernah berlangganan, 2. untuk orang yg belum pernah berlangganan. Promosi yang ditampilkan akan berbeda pada halaman akun pelanggan, 3. untuk orang yang sudah pernah ditawari secara langsung oleh pihak Travel Insurance namun belum tertarik untuk menjadi customer yang di nilai sangat berpotensi menjadi nasabah Travel Insurance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00fe0fe-1c26-4286-afbd-fb750538bbb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52660443-5d8e-40fd-a757-72d064741947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melihat Skewness Data\n",
    "for i in range(0, len(nums)):\n",
    "  skew = df[nums[i]].skew(axis = 0, skipna = True)\n",
    "  print(f'{nums[i]}: {skew}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ecb2f-5885-416b-bef3-9b05859127ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa Informasi Statistik Data\n",
    "df[nums].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2dd7b-df76-4a1f-ac6b-76b4e1f9bfa3",
   "metadata": {},
   "source": [
    "Fitur-fitur numerikal yang dimiliki bersifat normal, dengan pembuktian:\n",
    "\n",
    "- Berdasarkan skewness dari fitur-fitur numerikal lebih kecil dari 1, dapat diketahui bahwa distribusi data bersifat normal.\n",
    "- Perbedaan antara nilai mean dan median dari fitur-fitur numerikal tidak signifikan, sehingga dapat diasumsikan bahwa distribusi data bersifat normal.\n",
    "\n",
    "Karena fitur-fitur numerikal bersifat normal, untuk penyeragaman values setiap feature dilakukan normalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8518201-9bd9-4699-bd93-d26e5e50d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Rescaling Fitur-fitur numerikal\n",
    "df['Age_norm'] = MinMaxScaler().fit_transform(df['Age'].values.reshape(len(df), 1))\n",
    "df['AnnualIncome_norm'] = MinMaxScaler().fit_transform(df['AnnualIncome'].values.reshape(len(df), 1))\n",
    "df['FamilyMembers_norm'] = MinMaxScaler().fit_transform(df['FamilyMembers'].values.reshape(len(df), 1))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d88957-68bd-4771-b281-c7cac4089d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafik Distribusi Data\n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "for i in enumerate(df.describe().columns):\n",
    "  plt.subplot(4,3,i[0]+1)\n",
    "  sns.distplot(df[i[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd1900-b16c-44b7-b222-016d277ac2db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04ea3f-6d08-48dd-ae6c-c665889c0c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa value sebelum Feature Encoding\n",
    "\n",
    "for col in cats:\n",
    "    print(f'''Value count kolom {col}:''')\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce06a9f-ecf5-40e0-982a-58cc674561c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding Categorical Columns: Employment Type, GraduateOrNot, FrequentFlyer, EverTravelledAbroad\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "columns = ['Employment Type','GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad']\n",
    "\n",
    "for cats in columns:\n",
    "    df[cats] = le.fit_transform(df[cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8a138-bc27-40c0-8107-7e1caf9d2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Categorical Columns: Income Group\n",
    "onehots = pd.get_dummies(df['IncomeGroup'], prefix='IncomeClass')\n",
    "df = df.join(onehots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d0985-bbfc-4c97-857d-48c11e5292fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27013ee-094f-48e5-a5ff-147d1c160488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa value setelah Feature Encoding\n",
    "\n",
    "for col in columns:\n",
    "    print(f'''Value count kolom {col}:''')\n",
    "    print(df[col].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeee384-0060-40e2-b650-f125d9ab63fa",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f02741-b173-43c2-8300-3590e7e3d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15)) # Melihat korelasi menggunakan heatmap\n",
    "sns.heatmap(df.corr(), cmap='Blues', annot=True, fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3d879-231e-49f3-a82e-87f15927eb05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad859a-63a3-4301-8851-f3eca90acc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191d781-de1e-42dd-9340-7c4bdbf8b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan Fitur dan Target\n",
    "X = df.drop(['Age', 'AnnualIncome', 'FamilyMembers', 'TravelInsurance', 'IncomeGroup'], axis=1)\n",
    "y = df['TravelInsurance']\n",
    "\n",
    "# Melihat ukuran fitur dan target\n",
    "print(f'Shape of Features: {X.shape}')\n",
    "print(f'Shape of Target: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74535f6c-069b-4927-bf03-bafa84294485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into Train and Test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Shape of train: ','\\n','X_train',X_train.shape,'y_train',y_train.shape)\n",
    "print('Shape of test: ','\\n','X_test',X_test.shape,'y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62231a-c88b-47b7-afb3-b65165e15d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memeriksa Class Imbalance\n",
    "target0 = X_train[y==0]\n",
    "target1 = X_train[y==1]\n",
    "\n",
    "print(f'target0 shape: {target0.shape} \\nPercentage: {round(target0.shape[0] / (target0.shape[0]+target1.shape[0])*100, 2)}%')\n",
    "print(f'target0 shape: {target1.shape} \\nPercentage: {round(target1.shape[0] / (target0.shape[0]+target1.shape[0])*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb1915-8176-4647-a66b-c1c6a607d836",
   "metadata": {},
   "source": [
    "Ditemukannya Class Imbalance pada kolom Response (Target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0482b364-6a18-4fe3-a370-fb3e07de5c76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871dd41-7d95-449c-abbd-7e7965d04540",
   "metadata": {},
   "source": [
    "Karena terdapat imbalance pada data train, maka diputuskan untuk melakukan oversampling dengan metode SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940f526-9bc5-4e51-b03d-c456331980fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import over_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbe36c-1d47-4f68-8b09-06338b13d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling menggunakan SMOTE\n",
    "X_over_SMOTE, y_over_SMOTE = over_sampling.SMOTE(random_state=42).fit_resample(X, y)\n",
    "print('SMOTE')\n",
    "print(pd.Series(y_over_SMOTE).value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
